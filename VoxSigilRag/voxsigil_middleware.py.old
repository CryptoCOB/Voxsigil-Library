#!/usr/bin/env # Import V# Import VoxSigil RAG functionality
# Use standardized imports
try:
    # First try the package import
    from VoxSigilRag.voxsigil_rag import VoxSigilRAG
except ImportError:
    # Fall back to local import if package import fails
    try:
        from voxsigil_rag import VoxSigilRAG
    except ImportError:
        raise ImportError("Failed to import VoxSigilRAG. Make sure it's available in your path.")
# Use standardized imports
try:
    # First try the package import
    from VoxSigilRag.voxsigil_rag import VoxSigilRAG
except ImportError:
    # Fall back to local import if package import fails
    try:
        from voxsigil_rag import VoxSigilRAG
    except ImportError:
        raise ImportError("Failed to import VoxSigilRAG. Make sure it's available in your path.")
"""
VoxSigil Middleware for Runtime RAG Injection

This module provides middleware functionality for dynamically injecting
VoxSigil context during a conversation session.
"""

import logging
import json
import re # For FEATURE 2
from typing import Dict, Any, List, Optional, Tuple, Callable
from pathlib import Path
from collections import deque # For FEATURE 10

# Import VoxSigil RAG functionality
# TODO: Update path after reorganization is complete
from VoxSigilRag.voxsigil_rag import VoxSigilRAG # Current import
# Future import after reorganization:
# from VoxSigilRAG.voxsigil_rag import VoxSigilRAG

# For FEATURE 8 (Enhanced Grounding)
try:
    import numpy as np
    from sentence_transformers import util as sbert_util
    HAVE_SBERT_FOR_GROUNDING = True
except ImportError:
    HAVE_SBERT_FOR_GROUNDING = False
    logging.warning("sentence-transformers not fully available for advanced grounding. Semantic grounding will be basic.")


# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class VoxSigilMiddleware:
    """
    Middleware for dynamically injecting VoxSigil context at runtime.
    """

    def __init__(self,
                 voxsigil_rag_instance: Optional[VoxSigilRAG] = None,
                 conversation_history_size: int = 5,
                 # Default RAG parameters
                 num_sigils: int = 5,
                 min_score_threshold: float = 0.4,
                 detail_level: str = "standard",
                 include_explanations: bool = True,
                 # FEATURE 5: Conditional RAG
                 rag_off_keywords: Optional[List[str]] = None,
                 min_prompt_len_for_rag: int = 5,
                 # FEATURE 10: History Truncation
                 history_truncation_strategy: str = "tail", # "tail", "head", "head_and_tail"
                 # FEATURE 3: Intent-driven filtering
                 enable_intent_detection: bool = False # Simple flag
                 ):
        """
        Initialize the VoxSigil Middleware.

        Args:
            voxsigil_rag_instance: VoxSigil RAG instance (creates a new one if None)
            conversation_history_size: Max turns for history context and storage.
            num_sigils: Default max sigils to include.
            min_score_threshold: Default min score for sigils.
            detail_level: Default detail level for sigil formatting.
            include_explanations: Default for including retrieval explanations.
            rag_off_keywords: Keywords in user prompt to disable RAG for the turn.
            min_prompt_len_for_rag: Minimum length of user prompt content to trigger RAG.
            history_truncation_strategy: How to truncate history if it exceeds size.
            enable_intent_detection: Flag to enable basic intent detection for tag filtering.
        """
        self.voxsigil_rag = voxsigil_rag_instance or VoxSigilRAG()
        
        # Fix relationship format in loaded sigils to ensure schema validation passes
        if self.voxsigil_rag:
            self._normalize_sigil_relationships_format()
            
        self.conversation_history_size = conversation_history_size
        
        # Default RAG params (can be overridden per turn)
        self.default_rag_params = {
            "num_sigils": num_sigils,
            "min_score_threshold": min_score_threshold,
            "detail_level": detail_level,
            "include_explanations": include_explanations,
            # Add other relevant defaults from voxsigil_rag.inject_voxsigil_context if needed
            "filter_tags": None,
            "exclude_tags": None,
            "augment_query_flag": True,
            "apply_recency_boost_flag": True,
            "enable_context_optimizer": False, # Default to off for middleware simplicity initially
            "max_context_chars_budget": None, # Changed from tokens to chars to match RAG module
        }
        
        self.conversation_history: deque[Dict[str, Any]] = deque(maxlen=conversation_history_size) # Use deque
        self.selected_sigils_history: Dict[int, List[Dict[str, Any]]] = {} # Stores sigils per turn_id (request-response cycle)
        self.turn_counter = 0 # To uniquely ID turns for sigil history

        # FEATURE 5: Conditional RAG
        self.rag_off_keywords = [kw.lower() for kw in rag_off_keywords] if rag_off_keywords else ["@@norag@@", "norag"]
        self.min_prompt_len_for_rag = min_prompt_len_for_rag
        
        # FEATURE 6: Session-Scoped RAG Cache
        self._rag_cache: Dict[Tuple[Any, ...], Tuple[str, List[Dict[str, Any]]]] = {} # (rag_query_key_tuple) -> (enhanced_prompt, retrieved_sigils)

        # FEATURE 10: History Truncation
        self.history_truncation_strategy = history_truncation_strategy

        # FEATURE 3: Intent Detection
        self.enable_intent_detection = enable_intent_detection
        # Simple intent map for demo
        self.intent_to_tags_map: Dict[str, List[str]] = {
            "explain_concept": ["definition", "core_concept", "principle"],
            "find_example": ["example", "how_to", "usage"],
            "compare_options": ["comparison", "trade_off", "alternative"],
        }
    
    def _normalize_sigil_relationships_format(self):
        """
        Ensure all loaded sigil relationships are in the proper dictionary format.
        Converts list-format relationships to dictionary with unique keys.
        This method is called during initialization to ensure schema validation passes.
        """
        if not self.voxsigil_rag._loaded_sigils:
            # Load sigils if not already loaded
            self.voxsigil_rag.load_all_sigils(force_reload=False)
            
        if not self.voxsigil_rag._loaded_sigils:
            logger.warning("No sigils loaded to normalize relationships format.")
            return
            
        normalized_count = 0
        for sigil in self.voxsigil_rag._loaded_sigils:
            normalized_sigil = self._normalize_single_sigil_relationships(sigil)
            if normalized_sigil != sigil:
                normalized_count += 1
                
        if normalized_count > 0:
            logger.info(f"Normalized relationships format for {normalized_count} sigils")
            
            # Clear the sigil cache to force revalidation with the normalized format
            if hasattr(self.voxsigil_rag, '_sigil_cache'):
                self.voxsigil_rag._sigil_cache = {}
                
            # Force reload to apply schema validation with fixed relationships
            self.voxsigil_rag.load_all_sigils(force_reload=True)

    def _normalize_single_sigil_relationships(self, sigil: Dict[str, Any]) -> Dict[str, Any]:
        """
        Normalize relationships format for a single sigil to ensure schema compatibility.
        
        Args:
            sigil: The sigil dictionary to normalize
            
        Returns:
            The normalized sigil dictionary
        """
        if 'relationships' not in sigil:
            return sigil
            
        if not isinstance(sigil['relationships'], dict):
            # Found relationships that need to be converted from list/other format to dictionary
            if isinstance(sigil['relationships'], list):
                # Convert list of relationships to dictionary with unique keys
                relations_dict = {}
                
                for i, rel in enumerate(sigil['relationships']):
                    # Generate a unique key based on the relationship value or index
                    if isinstance(rel, str):
                        # If it's a string, use it as a value with a generated key
                        key = f"relation_{i+1}"
                        relations_dict[key] = rel
                    elif isinstance(rel, dict) and len(rel) == 1:
                        # If it's a dictionary with a single key-value pair, use it directly
                        key, value = next(iter(rel.items()))
                        relations_dict[key] = value
                    else:
                        # For other types, create a key based on index
                        key = f"relation_{i+1}"
                        relations_dict[key] = rel
                        
                sigil['relationships'] = relations_dict
            else:
                # If it's not a list or dict, convert to a simple dict with a default key
                sigil['relationships'] = {"default": sigil['relationships']}
                
        return sigil

    def _detect_intent(self, text: str) -> Optional[str]:
        """FEATURE 3: Basic intent detection placeholder."""
        if not self.enable_intent_detection:
            return None
        text_lower = text.lower()
        if "explain" in text_lower or "what is" in text_lower or "define" in text_lower or "tell me about" in text_lower:
            return "explain_concept"
        if "example" in text_lower or "show me how" in text_lower or "how do i use" in text_lower:
            return "find_example"
        if "compare" in text_lower or "difference between" in text_lower or "vs" in text_lower or "pros and cons" in text_lower:
            return "compare_options"
        return None

    def _get_focused_history_for_rag_query(self, current_prompt: str) -> str:
        """
        FEATURE 4: Generate a context string from conversation history for RAG query.
        More focused than just all history.
        """
        if not self.conversation_history:
            return ""
            
        context_parts = []
        history_list = list(self.conversation_history)

        last_user_msg_content: Optional[str] = None
        last_assistant_msg_content: Optional[str] = None

        for turn in reversed(history_list):
            if turn.get('role') == 'user' and not last_user_msg_content:
                last_user_msg_content = turn.get('content')
            elif turn.get('role') == 'assistant' and not last_assistant_msg_content:
                last_assistant_msg_content = turn.get('content')
            if last_user_msg_content and last_assistant_msg_content:
                break
        
        # Order to make sense for query: last user, then last assistant before that.
        if last_user_msg_content:
            context_parts.append(f"Previous User Input: {last_user_msg_content}")
        if last_assistant_msg_content:
            context_parts.append(f"Previous Assistant Response: {last_assistant_msg_content}")
            
        return "\n".join(reversed(context_parts)) # Chronological for context string

    def _parse_dynamic_rag_config(self, text: str) -> Tuple[str, Dict[str, Any]]:
        """FEATURE 2: Parses @@voxsigil_config:{...}@@ from text."""
        config: Dict[str, Any] = {}
        # Regex updated to voxsigil_config
        config_match = re.search(r"@@voxsigil_config:({.*?})@@", text, re.IGNORECASE)
        if config_match:
            try:
                config_str = config_match.group(1)
                config = json.loads(config_str)
                text = text.replace(config_match.group(0), "").strip() # Remove from text
                logger.info(f"Parsed dynamic VoxSigil RAG config: {config}")
            except json.JSONDecodeError:
                logger.warning(f"Invalid JSON in @@voxsigil_config: {config_str}")
        return text, config

    def preprocess_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """
        Preprocess the request before sending to the LLM.
        Injects VoxSigil context based on current prompt and history.
        """
        self.turn_counter += 1
        current_turn_id = self.turn_counter

        original_messages = request.get('messages', [])
        if not original_messages:
            logger.warning("No messages in request. Skipping VoxSigil RAG.")
            return request

        # Add new user messages to history. Deque handles maxlen.
        for msg in original_messages:
            # Add a simplified version to history if it's the new user message.
            # The assumption here is that `original_messages` contains the newest message.
            # More robust history management would involve message IDs or timestamps.
            # For this logic, we add user messages as they come in.
            if msg.get('role') == 'user':
                 # Only add if it's not effectively a duplicate of the last one added
                 # This needs a better check if dealing with retries etc.
                 if not self.conversation_history or self.conversation_history[-1] != msg :
                    self.conversation_history.append(msg.copy()) # Add a copy to history


        user_message_content = ""
        user_message_index = -1
        # Find the last user message in the current request batch
        for i, msg in reversed(list(enumerate(original_messages))):
            if msg.get('role') == 'user':
                user_message_content = msg.get('content', '')
                user_message_index = i
                break
                
        if not user_message_content:
            logger.warning("No user message content found in request. Skipping VoxSigil RAG.")
            self.selected_sigils_history[current_turn_id] = []
            return request

        # FEATURE 1 & 2: Resolve RAG parameters for this turn
        current_rag_params = self.default_rag_params.copy()
        if "voxsigil_rag_config" in request: 
            current_rag_params.update(request["voxsigil_rag_config"])
            logger.info(f"Using per-request VoxSigil RAG config: {request['voxsigil_rag_config']}")
        
        cleaned_user_message_content, dynamic_config = self._parse_dynamic_rag_config(user_message_content)
        current_rag_params.update(dynamic_config)
        if cleaned_user_message_content != user_message_content:
            user_message_content = cleaned_user_message_content
            if user_message_index != -1: # Ensure message is updated in request if cleaned
                 original_messages[user_message_index]['content'] = user_message_content
        
        # FEATURE 5: Conditional RAG Invocation
        prompt_lower_for_check = user_message_content.lower()
        if any(keyword in prompt_lower_for_check for keyword in self.rag_off_keywords):
            logger.info(f"VoxSigil RAG disabled for this turn due to keyword trigger in prompt.")
            self.selected_sigils_history[current_turn_id] = []
            return request
        # Check length based on words for more robustness than char count for "short"
        if len(user_message_content.split()) < self.min_prompt_len_for_rag:
            logger.info(f"VoxSigil RAG disabled for this turn due to short prompt length ({len(user_message_content.split())} words).")
            self.selected_sigils_history[current_turn_id] = []
            return request
            
        # FEATURE 4: Get focused history for RAG query context
        history_context_for_rag = self._get_focused_history_for_rag_query(user_message_content)
        
        rag_query_text = user_message_content
        if history_context_for_rag:
            rag_query_text = f"{history_context_for_rag}\n\nCURRENT USER QUERY: {user_message_content}"
        
        # FEATURE 3: Intent-Driven Sigil Filtering
        intent_tags = []
        detected_intent = self._detect_intent(user_message_content)
        if detected_intent and detected_intent in self.intent_to_tags_map:
            intent_tags = self.intent_to_tags_map[detected_intent]
            logger.info(f"Intent '{detected_intent}' detected for VoxSigil RAG, suggesting tags: {intent_tags}")
            existing_filter_tags = current_rag_params.get("filter_tags", []) or [] # Ensure it's a list
            current_rag_params["filter_tags"] = list(set(existing_filter_tags + intent_tags))

        # FEATURE 6: Session-Scoped RAG Cache Check
        # Make params hashable: sort dict items, then make tuple of tuples
        sorted_param_items = tuple(sorted(current_rag_params.items()))
        rag_cache_key = (rag_query_text, sorted_param_items)

        if rag_cache_key in self._rag_cache:
            logger.info("VoxSigil RAG Cache HIT for this query and params.")
            enhanced_prompt, retrieved_sigils = self._rag_cache[rag_cache_key]
        else:
            logger.info("VoxSigil RAG Cache MISS. Performing RAG injection.")
            try:
                # Ensure RAG instance is available
                if not self.voxsigil_rag:
                    raise ValueError("VoxSigilRAG instance is not initialized.")
                
                enhanced_prompt, retrieved_sigils = self.voxsigil_rag.inject_voxsigil_context(
                    prompt=user_message_content, 
                    query=rag_query_text,      
                    **current_rag_params       
                )
                
                # Normalize relationship format in retrieved sigils to ensure schema compatibility
                normalized_sigils = []
                for sigil in retrieved_sigils:
                    normalized_sigil = self._normalize_single_sigil_relationships(sigil)
                    normalized_sigils.append(normalized_sigil)
                
                # FEATURE 7: RAG Invocation Fallback
                if not normalized_sigils and current_rag_params.get("num_sigils", 0) > 0:
                    logger.warning("VoxSigil RAG call returned no sigils. This may be normal if query is niche or filters too strict.")
                
                self._rag_cache[rag_cache_key] = (enhanced_prompt, normalized_sigils)
                retrieved_sigils = normalized_sigils

            except Exception as e:
                logger.error(f"Error during VoxSigil RAG injection: {e}. Using original prompt.")
                # FEATURE 7: RAG Invocation Fallback
                enhanced_prompt = user_message_content 
                retrieved_sigils = []

        self.selected_sigils_history[current_turn_id] = retrieved_sigils
        
        if user_message_index != -1:
            original_messages[user_message_index]['content'] = enhanced_prompt
        
        request['messages'] = original_messages
        return request
    
    def postprocess_response(self, response: Dict[str, Any], scoring_enabled: bool = True) -> Dict[str, Any]:
        """Postprocess the LLM response, adding VoxSigil metadata and grounding scores."""
        
        current_turn_id = self.turn_counter 
        
        llm_message_content = ""
        # Standard OpenAI-like response structure
        if 'choices' in response and response['choices'] and isinstance(response['choices'][0], dict) and \
           'message' in response['choices'][0] and isinstance(response['choices'][0]['message'], dict):
            
            assistant_message = response['choices'][0]['message']
            # Add a copy of assistant's message to history if role is 'assistant'
            if assistant_message.get('role') == 'assistant':
                self.conversation_history.append(assistant_message.copy()) 
            llm_message_content = assistant_message.get('content', '')
        
        # Initialize voxsigil_metadata if not present
        if 'voxsigil_metadata' not in response: response['voxsigil_metadata'] = {}

        retrieved_sigils_for_turn = self.selected_sigils_history.get(current_turn_id, [])
        
        response['voxsigil_metadata']['turn_id'] = current_turn_id # Add turn ID for tracking
        
        if retrieved_sigils_for_turn:
            serializable_sigils = []
            for s_data in retrieved_sigils_for_turn:
                # Ensure all relevant fields are serializable and present
                sigil_info = {
                    'sigil': s_data.get('sigil', s_data.get('_source_file', 'unknown')),
                    'score': s_data.get('_similarity_score', 0.0),
                    'source_file': Path(s_data.get('_source_file', '')).name, # just filename
                    # Add other relevant fields if present in s_data like 'explanation'
                }
                if '_recency_boost_applied' in s_data:
                    sigil_info['recency_boost'] = s_data['_recency_boost_applied']
                if '_fusion_reason' in s_data:
                    sigil_info['fusion_reason'] = s_data['_fusion_reason']
                serializable_sigils.append(sigil_info)

            response['voxsigil_metadata']['retrieved_sigils'] = serializable_sigils
            
            if scoring_enabled and llm_message_content:
                scores = self.calculate_symbolic_grounding_scores(
                    llm_message_content, 
                    retrieved_sigils_for_turn 
                )
                response['voxsigil_metadata']['grounding_scores'] = scores
        else:
             response['voxsigil_metadata']['retrieved_sigils'] = [] # Ensure key exists

        # FEATURE 9: Sigil Usage Feedback Parsing (Conceptual)
        if llm_message_content:
            self._parse_llm_feedback_on_sigils(llm_message_content, retrieved_sigils_for_turn)
                
        return response

    def _parse_llm_feedback_on_sigils(self, llm_response_text: str, retrieved_sigils: List[Dict[str, Any]]):
        """FEATURE 9: Placeholder for parsing LLM's explicit feedback on sigil utility."""
        response_lower = llm_response_text.lower()
        for sigil_data in retrieved_sigils:
            s_name = sigil_data.get('sigil')
            if s_name and s_name.lower() in response_lower:
                # This is a very basic check; real NLP would be needed for accuracy
                if any(kw in response_lower for kw in ["helpful", "useful", "relevant", "good context"]):
                    logger.debug(f"LLM response might indicate sigil '{s_name}' was useful for VoxSigil context.")
                    # Potentially increment a 'usefulness_score' or log positive feedback for the sigil
                    # Example: self.voxsigil_rag.update_sigil_feedback(s_name, positive=True)
                elif any(kw in response_lower for kw in ["not relevant", "unhelpful", "confusing", "didn't use"]):
                    logger.debug(f"LLM response might indicate sigil '{s_name}' was NOT useful for VoxSigil context.")
                    # Example: self.voxsigil_rag.update_sigil_feedback(s_name, positive=False)
    
    def calculate_symbolic_grounding_scores(self, 
                                           response_text: str, 
                                           retrieved_sigils_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        FEATURE 8: Enhanced symbolic grounding for VoxSigil.
        Calculate scores based on how well LLM response aligns with retrieved sigils.
        """
        response_lower = response_text.lower()
        
        overall_scores: Dict[str, Any] = {
            'sigil_specific_scores': {}, # Scores per sigil
            'average_tag_inclusion': 0.0,
            'average_principle_adherence': 0.0,
            'weighted_overall_grounding': 0.0,
            'num_sigils_evaluated': 0
        }
        if not retrieved_sigils_data: return overall_scores

        total_retrieval_score_sum = sum(max(0.1, s.get('_similarity_score', 0.1)) for s in retrieved_sigils_data)
        if total_retrieval_score_sum == 0: total_retrieval_score_sum = 1.0 # Avoid division by zero for weights

        cumulative_tag_score_weighted = 0.0
        cumulative_principle_score_weighted = 0.0
        num_evaluated = 0

        response_embedding = None
        sbert_grounding_active = HAVE_SBERT_FOR_GROUNDING and self.voxsigil_rag and self.voxsigil_rag.embedding_model
        if sbert_grounding_active:
            try:
                response_embedding = self.voxsigil_rag.embedding_model.encode(response_text)
            except Exception as e:
                logger.warning(f"Could not generate response embedding for grounding: {e}")
                sbert_grounding_active = False # Disable for this run if problematic

        for sigil_item in retrieved_sigils_data:
            sigil_name = sigil_item.get('sigil', Path(sigil_item.get('_source_file', 'unknown')).name)
            retrieval_score_weight = max(0.1, sigil_item.get('_similarity_score', 0.1)) / total_retrieval_score_sum
            num_evaluated += 1
            
            current_sigil_tags = []
            if 'tag' in sigil_item and sigil_item['tag']: current_sigil_tags.append(str(sigil_item['tag']))
            if 'tags' in sigil_item:
                tags_val = sigil_item['tags']
                if isinstance(tags_val, list): current_sigil_tags.extend([str(t).lower() for t in tags_val])
                elif isinstance(tags_val, str): current_sigil_tags.append(tags_val.lower())
            
            sigil_tag_inclusion_score = 0.0
            if current_sigil_tags:
                tag_matches = sum(1 for tag in set(current_sigil_tags) if tag in response_lower) # Use set for unique tags
                sigil_tag_inclusion_score = tag_matches / len(set(current_sigil_tags))
            cumulative_tag_score_weighted += sigil_tag_inclusion_score * retrieval_score_weight
            
            sigil_principle_adherence = 0.0
            principle_text = sigil_item.get('principle', '')
            if principle_text:
                if sbert_grounding_active and response_embedding is not None:
                    try:
                        principle_embedding = self.voxsigil_rag.embedding_model.encode(principle_text)
                        # Cosine similarity ranges from -1 to 1. Normalize to 0-1 for scoring.
                        semantic_similarity = sbert_util.pytorch_cos_sim(response_embedding, principle_embedding).item()
                        sigil_principle_adherence = (semantic_similarity + 1) / 2 
                    except Exception as e:
                        logger.debug(f"Semantic principle check failed for sigil {sigil_name}: {e}. Falling back to keyword for this sigil.")
                        sbert_grounding_active_for_sigil = False # Fallback for this sigil only
                
                if not (sbert_grounding_active and response_embedding is not None) or (sbert_grounding_active and principle_text and sigil_principle_adherence == 0.0): # If SBERT failed or gave 0
                    key_phrases = [p.strip().lower() for p in principle_text.split('.') if len(p.strip()) > 10][:3] # Max 3 key phrases from principle
                    if key_phrases:
                        phrase_matches = sum(1 for phrase in key_phrases if phrase in response_lower)
                        sigil_principle_adherence = phrase_matches / len(key_phrases)
            cumulative_principle_score_weighted += sigil_principle_adherence * retrieval_score_weight
            
            overall_scores['sigil_specific_scores'][sigil_name] = {
                'tag_inclusion': round(sigil_tag_inclusion_score, 3),
                'principle_adherence': round(sigil_principle_adherence, 3),
                'retrieval_weight': round(retrieval_score_weight, 3)
            }

        if num_evaluated > 0:
            overall_scores['average_tag_inclusion'] = round(cumulative_tag_score_weighted, 3) # Already weighted by retrieval score sum
            overall_scores['average_principle_adherence'] = round(cumulative_principle_score_weighted, 3)
            overall_scores['weighted_overall_grounding'] = round(
                (overall_scores['average_tag_inclusion'] * 0.4) + (overall_scores['average_principle_adherence'] * 0.6), 3
            )
        overall_scores['num_sigils_evaluated'] = num_evaluated
                           
        return overall_scores
        
    def wrap_llm_api(self, llm_api_call: Callable[..., Any]) -> Callable[..., Any]:
        """Wrap an LLM API call with VoxSigil middleware."""
        def wrapped_llm_api(*args: Any, **kwargs: Any) -> Any:
            request_dict: Optional[Dict[str, Any]] = None
            is_kwargs_request = False

            if 'request' in kwargs and isinstance(kwargs['request'], dict):
                request_dict = kwargs['request']
                is_kwargs_request = True
            elif args and isinstance(args[0], dict) and 'messages' in args[0]: # Heuristic for positional arg
                request_dict = args[0]
            
            if not request_dict:
                logger.warning("No suitable request dictionary found in API call args/kwargs. Skipping VoxSigil middleware.")
                return llm_api_call(*args, **kwargs)
                
            # Operate on a copy to avoid modifying original request object in caller's scope unintentionally
            processed_request = self.preprocess_request(request_dict.copy()) 
            
            if is_kwargs_request:
                kwargs['request'] = processed_request
            elif args: # Positional arg case
                args = (processed_request,) + args[1:]
                
            raw_response = llm_api_call(*args, **kwargs)
            
            if isinstance(raw_response, dict):
                 # Operate on a copy for postprocessing
                 final_response = self.postprocess_response(raw_response.copy())
                 return final_response
            else:
                logger.warning(f"LLM API call did not return a dictionary. Response type: {type(raw_response)}. Skipping VoxSigil postprocessing.")
                return raw_response # Return as-is if not a dict
            
        return wrapped_llm_api


if __name__ == "__main__":
    # Setup a dummy VoxSigilRAG instance
    test_lib_base_path = Path("VoxSigil-Library-Test") # Renamed library path
    sigils_dir_path = test_lib_base_path / "core" # Matching structure in RAG example
    
    if not test_lib_base_path.exists() or not any(sigils_dir_path.iterdir() if sigils_dir_path.exists() else []):
        logger.warning(f"Test VoxSigil library at {test_lib_base_path} (or subdir {sigils_dir_path.name}) is missing or empty. RAG might not retrieve sigils.")
        test_lib_base_path.mkdir(parents=True, exist_ok=True)
        sigils_dir_path.mkdir(parents=True, exist_ok=True)
        dummy_sigil_content = {
            "sigil": "DummySigil", "principle": "This is a dummy principle for testing all systems.",
            "tags": ["dummy", "test_infra", "core_concept"], "usage": {"description": "Use for dummy tests of middleware."}
        }
        # Use .voxsigil extension as per RAG module changes
        with open(sigils_dir_path / "dummy_middleware.voxsigil", 'w') as f: 
            json.dump(dummy_sigil_content, f) # json.dump for .voxsigil if it's treated as json/yaml

    # Assuming VoxSigilRAG class is correctly defined and imported
    try:
        test_voxsigil_rag = VoxSigilRAG(voxsigil_library_path=test_lib_base_path)
        test_voxsigil_rag.load_all_sigils(force_reload=True) # Ensure it loads from the test path
        if HAVE_SBERT_FOR_GROUNDING: # Only precompute if SentenceTransformers available
            test_voxsigil_rag.precompute_all_embeddings(force_recompute=True)
    except Exception as e:
        logger.error(f"Failed to initialize VoxSigilRAG for testing: {e}")
        # Fallback to a mock/dummy RAG if full init fails, to test middleware structure
        class MockVoxSigilRAG: # type: ignore
            embedding_model = None # For grounding check
            def inject_voxsigil_context(self, prompt, query, **kwargs):
                logger.info(f"[MockRAG] Injecting context for query: {query[:50]}...")
                return f"CONTEXT-INJECTED: {prompt}", [{"sigil":"MockSigil", "_similarity_score":0.9, "_source_file":"mock.voxsigil"}]
        test_voxsigil_rag = MockVoxSigilRAG() # type: ignore

    middleware = VoxSigilMiddleware(
        voxsigil_rag_instance=test_voxsigil_rag,
        conversation_history_size=3,
        num_sigils=2,
        min_score_threshold=0.1 
    )
    
    def mock_llm_api(request: Dict[str, Any]) -> Dict[str, Any]:
        user_msg = request['messages'][-1]['content']
        logger.info(f"\n[Mock LLM API In] User Message (first 100 chars): '{user_msg[:100]}...'")
        
        response_content = f"LLM thought: Okay, user asked about '{user_msg[:50]}...'. "
        if "DummySigil" in user_msg or "DummySigil" in str(request): # Check if sigil name present from RAG
             response_content += "The DummySigil with its dummy principle seems relevant here. "
             response_content += "The tags 'dummy' and 'test_infra' from the VoxSigil context are noted. "
        else:
            response_content += "No specific sigils were emphasized in the RAG context for this turn. "
        response_content += "Generic response."

        return {
            'choices': [{'message': {'role': 'assistant', 'content': response_content}}],
            "usage": {"prompt_tokens": 50, "completion_tokens": 30, "total_tokens": 80}
        }
    
    wrapped_api = middleware.wrap_llm_api(mock_llm_api)
    
    logger.info("\n--- Test Case 1: Simple query (expecting RAG) ---")
    test_request_1 = {'messages': [{'role': 'user', 'content': 'Tell me about symbolic reasoning and AI integration.'}]}
    response_1 = wrapped_api(request=test_request_1.copy())
    print("\nResponse 1 (JSON):"); print(json.dumps(response_1, indent=2))

    logger.info("\n--- Test Case 2: Query with dynamic VoxSigil RAG config in message ---")
    test_request_2 = {'messages': [{'role': 'user', 'content': 'System details. @@voxsigil_config:{"num_sigils": 1, "detail_level": "summary"}@@'}]}
    response_2 = wrapped_api(request=test_request_2.copy())
    print("\nResponse 2 (JSON):"); print(json.dumps(response_2, indent=2))

    logger.info("\n--- Test Case 3: Query with per-request VoxSigil RAG config override ---")
    test_request_3 = {
        'messages': [{'role': 'user', 'content': 'What are some test sigils, specifically for infrastructure?'}],
        'voxsigil_rag_config': {"num_sigils": 1, "filter_tags": ["test_infra"], "min_score_threshold": 0.05}
    }
    response_3 = wrapped_api(request=test_request_3.copy())
    print("\nResponse 3 (JSON):"); print(json.dumps(response_3, indent=2))

    logger.info("\n--- Test Case 4: Query that should disable RAG (keyword) ---")
    test_request_4 = {'messages': [{'role': 'user', 'content': 'Please, no RAG for this one. @@norag@@'}]}
    response_4 = wrapped_api(request=test_request_4.copy())
    print("\nResponse 4 (JSON):"); print(json.dumps(response_4, indent=2))

    logger.info("\n--- Test Case 5: Follow-up query, testing history focus for RAG ---")
    # Middleware's history should now contain request 3 and its response
    test_request_5 = {'messages': [{'role': 'user', 'content': 'Expand on the first sigil you retrieved for the infrastructure query.'}]}
    response_5 = wrapped_api(request=test_request_5.copy())
    print("\nResponse 5 (JSON):"); print(json.dumps(response_5, indent=2))
    
    logger.info("\n--- Test Case 6: Query with intent detection hint for filtering ---")
    middleware.enable_intent_detection = True # Enable for this test
    test_request_6 = {'messages': [{'role': 'user', 'content': 'Can you explain the core concept of dummy sigils?'}]}
    response_6 = wrapped_api(request=test_request_6.copy())
    middleware.enable_intent_detection = False 
    print("\nResponse 6 (JSON with intent hint for RAG):"); print(json.dumps(response_6, indent=2))

    logger.info("\n--- Test Case 7: Short query to test min_prompt_len_for_rag ---")
    middleware.min_prompt_len_for_rag = 3 # Set to 3 words for this test
    test_request_7_short = {'messages': [{'role': 'user', 'content': 'Hi there.'}]} # 2 words
    response_7_short = wrapped_api(request=test_request_7_short.copy())
    print("\nResponse 7 (short prompt, RAG should be disabled):"); print(json.dumps(response_7_short, indent=2))
    
    test_request_7_ok = {'messages': [{'role': 'user', 'content': 'Hello, how are you?'}]} # 4 words
    response_7_ok = wrapped_api(request=test_request_7_ok.copy())
    print("\nResponse 7 (ok prompt length, RAG should be enabled):"); print(json.dumps(response_7_ok, indent=2))
    
    # Cleanup test directory
    try:
        import shutil
        if test_lib_base_path.exists():
            shutil.rmtree(test_lib_base_path)
            logger.info(f"Cleaned up test directory: {test_lib_base_path}")
    except Exception as e:
        logger.error(f"Error cleaning up test directory {test_lib_base_path}: {e}")

    logger.info("\n--- VoxSigil Middleware Test Run Finished ---")