#!/usr/bin/env python
"""
VoxSigil Training Pipeline Verification Report
Analyzes and verifies: ARC data usage, VantaCore data generation,
component training, GPU utilization, and accuracy plateauing
"""

import json
import logging
import os
import sys
import time
from pathlib import Path

# Add the library path
sys.path.insert(0, str(Path(__file__).parent))

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("VoxSigilVerification")


def verify_arc_data_usage():
    """Verify ARC data loading and usage"""
    logger.info("üîç VERIFYING ARC DATA USAGE")
    print("=" * 60)

    # Check if ARC data exists
    arc_data_path = "arc_data"
    if os.path.exists(arc_data_path):
        print(f"‚úÖ ARC data directory found: {arc_data_path}")

        # Check for required files
        required_files = ["training.json", "evaluation.json"]
        for file in required_files:
            file_path = os.path.join(arc_data_path, file)
            if os.path.exists(file_path):
                try:
                    with open(file_path, "r") as f:
                        data = json.load(f)
                    print(f"‚úÖ {file}: {len(data)} tasks available")
                except Exception as e:
                    print(f"‚ùå {file}: Error loading - {e}")
            else:
                print(f"‚ùå {file}: Missing")
    else:
        print(f"‚ùå ARC data directory not found: {arc_data_path}")

    # Test ARC data processor
    try:
        from ARC.arc_data_processor import ARCGridDataProcessor

        processor = ARCGridDataProcessor(max_grid_size=30)
        print("‚úÖ ARCGridDataProcessor initialized successfully")

        # Test data loading with current path structure
        if os.path.exists(arc_data_path):
            try:
                # Try to load the data
                challenges_path = os.path.join(arc_data_path, "training.json")
                tasks = processor.load_arc_data(challenges_path)
                print(f"‚úÖ Successfully loaded {len(tasks)} ARC tasks")

                # Check data structure
                first_task = list(tasks.values())[0]
                if "train" in first_task and "test" in first_task:
                    print("‚úÖ ARC data structure is valid")
                    print(f"   Training examples: {len(first_task['train'])}")
                    print(f"   Test examples: {len(first_task['test'])}")
                else:
                    print("‚ùå Invalid ARC data structure")

            except Exception as e:
                print(f"‚ùå Error loading ARC data: {e}")

    except Exception as e:
        print(f"‚ùå ARCGridDataProcessor not available: {e}")


def verify_vantacore_data_generation():
    """Verify VantaCore data generation capabilities"""
    logger.info("üè≠ VERIFYING VANTACORE DATA GENERATION")
    print("=" * 60)

    try:
        from Vanta.core.UnifiedVantaCore import UnifiedVantaCore as VantaCore

        print("‚úÖ VantaCore imported successfully")

        # Test VantaCore initialization
        try:
            # Initialize with proper parameters based on actual constructor
            vanta_core = VantaCore()
            print("‚úÖ VantaCore initialized successfully")

            # Check available methods
            vanta_methods = [
                method for method in dir(vanta_core) if not method.startswith("_")
            ]
            data_related_methods = [
                m
                for m in vanta_methods
                if any(
                    keyword in m.lower()
                    for keyword in ["data", "generate", "create", "process", "enhance"]
                )
            ]

            print(f"‚úÖ VantaCore has {len(vanta_methods)} public methods")
            print(f"‚úÖ Data-related methods: {len(data_related_methods)}")
            for method in data_related_methods[:5]:  # Show first 5
                print(f"   - {method}")

            # Test if VantaCore can process/enhance data
            test_success = False
            for method_name in ["process", "enhance", "transform"]:
                if hasattr(vanta_core, method_name):
                    print(f"‚úÖ VantaCore has {method_name} method for data processing")
                    test_success = True
                    break

            if not test_success:
                print("‚ö†Ô∏è No obvious data processing methods found")

        except Exception as e:
            print(f"‚ùå Error initializing VantaCore: {e}")

    except Exception as e:
        print(f"‚ùå VantaCore not available: {e}")


def verify_component_training():
    """Verify component training capabilities"""
    logger.info("üß© VERIFYING COMPONENT TRAINING")
    print("=" * 60)

    components_to_check = {
        "ARCGridTrainer": {
            "module": "training.arc_grid_trainer",
            "class": "ARCGridTrainer",
            "methods": ["train", "start_coordinated_training"],
        },
        "GRID_Former": {
            "module": "core.grid_former",
            "class": "GRID_Former",
            "methods": ["forward", "train"],
        },
        "BLTEncoder": {
            "module": "BLT.blt_encoder",
            "class": "BLTEncoder",
            "methods": ["encode", "train"],
        },
        "VoxSigilRAG": {
            "module": "VoxSigilRag.voxsigil_blt_rag",
            "class": "BLTEnhancedRAG",
            "methods": ["process", "query"],
        },
        "HOLOMesh": {
            "module": "agents.holo_mesh",
            "class": "HOLOMesh",
            "methods": ["activate", "process"],
        },
        "NovelReasoning": {
            "module": "core.novel_reasoning.logical_neural_units",
            "class": "LogicalReasoningEngine",
            "methods": ["forward", "reason"],
        },
    }

    available_components = 0
    trainable_components = 0

    for comp_name, comp_info in components_to_check.items():
        try:
            module = __import__(comp_info["module"], fromlist=[comp_info["class"]])
            component_class = getattr(module, comp_info["class"])
            print(f"‚úÖ {comp_name} available")
            available_components += 1

            # Check for training methods
            has_training = False
            for method in comp_info["methods"]:
                if hasattr(component_class, method):
                    print(f"   ‚úÖ Has {method} method")
                    has_training = True

            if has_training:
                trainable_components += 1
                print(f"   ‚úÖ {comp_name} is trainable")
            else:
                print(f"   ‚ö†Ô∏è {comp_name} may not be trainable")

        except Exception as e:
            print(f"‚ùå {comp_name} not available: {e}")

    print("\nüìä Component Summary:")
    print(f"   Available: {available_components}/{len(components_to_check)}")
    print(f"   Trainable: {trainable_components}/{len(components_to_check)}")


def verify_gpu_utilization():
    """Verify GPU utilization setup"""
    logger.info("üöÄ VERIFYING GPU UTILIZATION")
    print("=" * 60)

    try:
        import torch

        print("‚úÖ PyTorch available")

        if torch.cuda.is_available():
            device_count = torch.cuda.device_count()
            print(f"‚úÖ CUDA available with {device_count} GPU(s)")

            for i in range(device_count):
                device_name = torch.cuda.get_device_name(i)
                # Get memory info
                torch.cuda.empty_cache()  # Clear cache for accurate reading
                memory_allocated = torch.cuda.memory_allocated(i) / (1024**3)
                memory_reserved = torch.cuda.memory_reserved(i) / (1024**3)
                total_memory = torch.cuda.get_device_properties(i).total_memory / (
                    1024**3
                )

                print(f"   GPU {i}: {device_name}")
                print(f"     Total Memory: {total_memory:.2f}GB")
                print(f"     Allocated: {memory_allocated:.2f}GB")
                print(f"     Reserved: {memory_reserved:.2f}GB")
                print(f"     Available: {total_memory - memory_reserved:.2f}GB")

            # Test GPU tensor operations
            try:
                test_tensor = torch.randn(1000, 1000).cuda()
                result = torch.matmul(test_tensor, test_tensor.t())
                print("‚úÖ GPU tensor operations working")
                del test_tensor, result
                torch.cuda.empty_cache()
            except Exception as e:
                print(f"‚ùå GPU tensor operation failed: {e}")

            return True
        else:
            print("‚ùå CUDA not available - training will use CPU")
            print("   This may explain accuracy plateauing due to slower training")
            return False

    except Exception as e:
        print(f"‚ùå PyTorch not available: {e}")
        return False


def verify_training_pipeline():
    """Verify the complete training pipeline"""
    logger.info("üîß VERIFYING TRAINING PIPELINE")
    print("=" * 60)

    try:
        from training.arc_grid_trainer import ARCGridTrainer

        print("‚úÖ ARCGridTrainer imported")

        # Test trainer initialization
        try:
            config = {
                "grid_size": 30,
                "use_cuda": True,
                "arc_data_path": "./arc_data",
                "use_art": True,
                "use_holo_mesh": True,
                "use_novel_paradigms": True,
            }

            trainer = ARCGridTrainer(config=config)
            print("‚úÖ ARCGridTrainer initialized successfully")

            # Check critical methods
            critical_methods = [
                "start_coordinated_training",
                "_initialize_vanta_core",
                "_initialize_novel_paradigms",
                "_initialize_holo_mesh",
                "_initialize_art",
            ]

            missing_methods = []
            for method in critical_methods:
                if hasattr(trainer, method):
                    print(f"   ‚úÖ Has {method}")
                else:
                    missing_methods.append(method)
                    print(f"   ‚ùå Missing {method}")

            if not missing_methods:
                print("‚úÖ All critical training methods available")

                # Test training initialization
                try:
                    training_config = {
                        "epochs": 5,
                        "batch_size": 16,
                        "learning_rate": 0.001,
                    }

                    success = trainer.start_coordinated_training(training_config)
                    if success:
                        print("‚úÖ Training pipeline can be started")
                    else:
                        print("‚ùå Training pipeline failed to start")

                except Exception as e:
                    print(f"‚ö†Ô∏è Training start test failed: {e}")
            else:
                print(f"‚ùå Missing critical methods: {missing_methods}")

        except Exception as e:
            print(f"‚ùå ARCGridTrainer initialization failed: {e}")

    except Exception as e:
        print(f"‚ùå ARCGridTrainer not available: {e}")


def analyze_accuracy_plateauing():
    """Analyze potential causes of accuracy plateauing"""
    logger.info("üìà ANALYZING ACCURACY PLATEAUING")
    print("=" * 60)

    potential_issues = []

    # Check data quality
    if not os.path.exists("arc_data"):
        potential_issues.append("‚ùå No real ARC data - using mock data limits learning")

    # Check GPU utilization
    try:
        import torch

        if not torch.cuda.is_available():
            potential_issues.append(
                "‚ùå No GPU acceleration - slower training affects convergence"
            )
    except:
        potential_issues.append(
            "‚ùå PyTorch not available - using fallback implementations"
        )

    # Check model complexity
    try:
        potential_issues.append("‚úÖ GRID_Former available - good model complexity")
    except:
        potential_issues.append(
            "‚ùå GRID_Former not available - using simplified models"
        )

    # Check ensemble integration
    try:
        potential_issues.append("‚úÖ Ensemble orchestrator available")
    except:
        potential_issues.append(
            "‚ùå Ensemble orchestrator missing - reduced model capacity"
        )

    print("üîç Potential causes of accuracy plateauing:")
    for issue in potential_issues:
        print(f"   {issue}")

    print("\nüí° Recommendations:")
    if any("mock data" in issue for issue in potential_issues):
        print("   üì• Download real ARC dataset for better training data")
    if any("No GPU" in issue for issue in potential_issues):
        print("   üöÄ Install CUDA-enabled PyTorch for faster training")
    if any("not available" in issue for issue in potential_issues):
        print("   üîß Install missing components for full model capacity")

    print("   üéØ Consider: Lower learning rate, longer training, data augmentation")
    print("   üìä Monitor: Loss curves, gradient norms, component utilization")


def main():
    """Run comprehensive verification"""
    logger.info("üîç STARTING VOXSIGIL TRAINING PIPELINE VERIFICATION")
    print("=" * 80)
    print("VoxSigil Training Pipeline Verification Report")
    print("=" * 80)

    start_time = time.time()

    # Run all verifications
    verify_arc_data_usage()
    print("\n")

    verify_vantacore_data_generation()
    print("\n")

    verify_component_training()
    print("\n")

    verify_gpu_utilization()
    print("\n")

    verify_training_pipeline()
    print("\n")

    analyze_accuracy_plateauing()

    # Final summary
    end_time = time.time()
    print("\n" + "=" * 80)
    print("üìã VERIFICATION COMPLETE")
    print("=" * 80)
    print(f"‚è±Ô∏è Verification took {end_time - start_time:.2f} seconds")
    print("\nüéØ Next Steps:")
    print("   1. Review any ‚ùå items above")
    print("   2. Run GUI training to test pipeline")
    print("   3. Monitor training metrics and GPU utilization")
    print("   4. Address accuracy plateauing causes identified")

    print("\n‚úÖ Verification report complete!")


if __name__ == "__main__":
    main()
